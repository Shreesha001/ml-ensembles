import numpy as np
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier
import matplotlib.pyplot as plt





df = pd.read_csv("heart.csv")


df.head()





cat_variables = ['Sex',
'ChestPainType',
'RestingECG',
'ExerciseAngina',
'ST_Slope'
]





df = pd.get_dummies(data = df, prefix = cat_variables, columns = cat_variables)


df


features = [x for x in df.columns if x!= 'HeartDisease'] ## Removing our target variable


features


len(features)


X_train, X_test, y_train, y_test = train_test_split( df[features], df['HeartDisease'], train_size = 0.8, random_state = 55)


print(f'train samples: {len(X_train)} validation samples: {len(X_test)}')

# target proportion" tells you how balanced your dataset is in terms of classes.
print(f'target proportion: {sum(y_train)/len(y_train):.4f}')





min_samples_split_list = [2,10, 30, 50, 100, 200, 300, 700]  
max_depth_list = [1, 2, 3, 4 , 8, 16, 32, 64, None]  


accuracy_list_train = []
accuracy_list_test = []

for min_samples_split in min_samples_split_list:
    model = DecisionTreeClassifier(min_samples_split=min_samples_split, random_state=55).fit(X_train, y_train)
    predictions_train = model.predict(X_train)
    predictions_test = model.predict(X_test)
    accuracy_train = accuracy_score(predictions_train, y_train)
    accuracy_test = accuracy_score(predictions_test, y_test)
    accuracy_list_train.append(accuracy_train)
    accuracy_list_test.append(accuracy_test)

plt.title('Train x Validation metrics')
plt.xlabel('min_samples_split')
plt.ylabel('accuracy')
# By default, matplotlib puts ticks as 0, 1, 2... (just index positions).
# But your real X-values are [2, 10, 30, 50, 100, 200, 300, 700] 
plt.xticks(ticks = range(len(min_samples_split_list)), labels=min_samples_split_list)
plt.plot(accuracy_list_train)
plt.plot(accuracy_list_test)
plt.legend(['Train','Validation'])






accuracy_list_train = []
accuracy_list_test = []

accuracy_list_train = []
accuracy_list_test = []
for max_depth in max_depth_list: 
    model = DecisionTreeClassifier(max_depth = max_depth, random_state = 55).fit(X_train,y_train) 
    predictions_train = model.predict(X_train)  
    predictions_test = model.predict(X_test)  
    accuracy_train = accuracy_score(predictions_train,y_train)
    accuracy_test = accuracy_score(predictions_test,y_test)
    accuracy_list_train.append(accuracy_train)
    accuracy_list_test.append(accuracy_test)

plt.title('Train x Validation metrics')
plt.xlabel('max_depth')
plt.ylabel('accuracy')
plt.xticks(ticks = range(len(max_depth_list )),labels=max_depth_list)
plt.plot(accuracy_list_train)
plt.plot(accuracy_list_test)
plt.legend(['Train','Validation'])





decision_tree_model = DecisionTreeClassifier(min_samples_split = 50,
                                             max_depth = 3,
                                             random_state = 55).fit(X_train,y_train)


print(f"Metrics train:\n\tAccuracy score: {accuracy_score(decision_tree_model.predict(X_train),y_train):.4f}")
print(f"Metrics validation:\n\tAccuracy score: {accuracy_score(decision_tree_model.predict(X_test),y_test):.4f}")



